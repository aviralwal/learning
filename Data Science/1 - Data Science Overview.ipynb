{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Science\n",
    "Data science is basically using data to answer questions. \n",
    "\n",
    "It can involve statistics, computer science, maths, data cleaning and formatting and data visualization.\n",
    "\n",
    "The need for data science has increased due to the generation of lot's of big data and need to extract some meaningful information from that data.\n",
    "\n",
    "**Data Scientist** can be defined as someone who combines programming, stats and domain knowledge to answer questions based on data.\n",
    "\n",
    "\n",
    "<center><img src=images/data_science-data_scientist.png width=\"60%\" /></center>\n",
    "\n",
    "There are 3 core components in data science as we can see from the venn diagram. We can define those as - \n",
    "* Hacking skills(or coding) - This is required since it helps gather and prepare data since it is present in unusual sources and requires some effort to get it and prepare it to allow some analysis. Some components required are - \n",
    "    * Programming Language - Python/R \n",
    "    * Databases - SQL/NoSQL\n",
    "* Maths & Statistical Knowledge(Math kn) - This is required since it helps to choose what process should be used to answer the questions by using the data and help diagnose problems when things don't go as planned. Some techniques that are required are Probability, Algebra, Regression, etc\n",
    "* Substantive Expertise(or domain knowledge) - Some kind of doimain expertise is also required, i.e., knowledge about the field in which we want to apply data science, like business setting, goals, methods, constraints, etc. It is imp since we need to implement whatever result we have achieved since DS is practical and we should be having sufficient knowledge on how we can implement the results to solve the problem in that domain.\n",
    "\n",
    "From P&C(Permutations and combinations) of these 3 fields, we derive the following - \n",
    "* ML - Combination of coding and math knowledge without any specific domain knowledge. These are \"black box\" models, i.e., we will input some data and get some output data without necessary knowling what the data is or knowledge about data\n",
    "* Research - Combination of domain knowledge and maths without coding. Data is structured and is ready for analysis. Effort is in method and interpretation of data.\n",
    "* Danger zone - Combination of coding and domain knowledge without math knowledge and is not likely to be used.\n",
    "\n",
    "So we see several fields make DS, a diverse set of skills is needed and there are many roles which are involved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data\n",
    "\n",
    "Data can be defined as \"A set of values of quantitative and qualitative variables\". __A set of values__ means that value population on which we are trying to discover something, __variables__ are the characterestics of the item, __qualitative__ means values which are non-numeric in nature and cannot be quantized, or we cannot tell the exact quantity and __quantitative__ means the values which we can tell the exact amount of.\n",
    "\n",
    "In data science, first we ask the questions and then use data to find answer to those questions. It might happen that due to data limitations, we might have to refraim the question but the data science is driven by question and not data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roles in Data Science \n",
    "There are multiple roles or types of people that are involved in DS process. They could be individuals in each field or people who have knowledge about multiple fields. Some of them are - \n",
    "* Engineers - Developers, DB admin, etc\n",
    "* Big data analysts\n",
    "* Researchers\n",
    "* Business analyst\n",
    "* Business domain knowledge people, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarcy of Data Science needs - \n",
    "<center><img src=images/data_science-hierarchy_of_needs.png width=\"60%\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms used in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental design concepts\n",
    "\n",
    "As a data scientist, we need to design a proper experiement to answer the questions. Experimental design is organizing an experiment so that you have the correct data (and enough of it!) to clearly and effectively answer your data science question. Before going into analysis, it is imp to have a plan on how we will proceed with the analysis of data since incorrect analysis can lead to incorrect answers for our questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal of experimental design\n",
    "\n",
    "* Independent variable (AKA factor): The variable that the experimenter manipulates; it does not depend on other variables being measured. Often displayed on the x-axis.\n",
    "\n",
    "* Dependent variable: The variable that is expected to change as a result of changes in the independent variable. Often displayed on the y-axis, so that changes in X, the independent variable, effect changes in Y.\n",
    "\n",
    "* Hypothesis: an educated guess of the relationship between variables and the outcome of the experiment.\n",
    "\n",
    "* Confounder: An extraneous variable that may affect the relationship between the dependent and independent variables.\n",
    "\n",
    "* Sample size: The number of experimental subjects you will include in your experiment\n",
    "\n",
    "* A control group is a group of subjects for which the independent variable is not changed but still have their dependent variables measured. This allows to take care of the confounder. There are multiple ways to create control groups to take care of confounder\n",
    "    * Blinded - it means that the control group is not aware that the independent variables are note being changed for it. It is generally done by using __placebo__ effect.\n",
    "    * Randomization - it means randomly distributing the subjects to control and experiment group to decrease the concentration of the confounder in any one place\n",
    "    * Replication - repeating the experiment multiple times with different experiment groups to give weightage to the foundings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big data\n",
    "\n",
    "Big data can be characterized by three qualities -\n",
    "<center><img src=images/data_science-big_data.png width=\"60%\" /></center>\n",
    "\n",
    "* **Volume** - involves large data sets. Some reasonse for this are increase in data sources, higher resolution sensors and scalable infra\n",
    "* **Velocity** - high speed of data generation in an non-stop process\n",
    "* **Variety** - there are several different types of data available. Also data comes from different sources.\n",
    "* **Veracity** - quality and origin of data.\n",
    "* **Value** - using the data to derive some value from it\n",
    "\n",
    "Given some of the qualities of big data above, you can already start seeing some of the challenges that may be associated with working with big data.\n",
    "\n",
    "* It is big: there is a lot of raw data that you need to be able to store and analyse;\n",
    "* It is constantly changing and updating: By the time you finish your analysis, there is even more new data you could incorporate into your analysis! Every second you are analysing, is another second of data you haven’t used!\n",
    "* The variety can be overwhelming: There are so many sources of information that it can sometimes be difficult to determine what source of data may be best suited to answer your data science question! And finally,\n",
    "* It is messy: You don’t have neat data tables to quickly analyse - you have messy data. Before you can start looking for answers, you need to turn your unstructured data into a format that you can analyse!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mining\n",
    "\n",
    "Processing of automatically searching and analysing data to see perviously unknown patterns using multiple tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![separator2](https://i.imgur.com/4gX5WFr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
